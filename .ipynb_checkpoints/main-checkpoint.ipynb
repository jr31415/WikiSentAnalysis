{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d239d6-5aaa-4d66-92b3-d0bcd1d0cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def samplestring_to_num(sampleoutput):\n",
    "    \"\"\"Takes a list (sample, output) where sample is \"Positive\", \"Negative\", \"Neutral\",\n",
    "    or \"Irrelevant\", and returns the same list, but the aforementioned terms are\n",
    "    replaced with 1, -1, 0, or None\n",
    "    \"\"\"\n",
    "    match sampleoutput[0]:\n",
    "        case \"Positive\":\n",
    "            return [0, sampleoutput[1]]\n",
    "        case \"Negative\":\n",
    "            return [1, sampleoutput[1]]\n",
    "        case \"Neutral\":\n",
    "            return [2, sampleoutput[1]]\n",
    "        case \"Irrelevant\":\n",
    "            return None\n",
    "\n",
    "def format_data(input_data):\n",
    "    \"\"\"Takes unformated data from training/validation, and formats it into a list\n",
    "\n",
    "    Input: input_data -- a string, represeting one line from twitter_training/validation\n",
    "    \"\"\"\n",
    "    data = next(csv.reader([input_data]))[2:]\n",
    "    return samplestring_to_num(data)\n",
    "    \n",
    "def create_data(data_csv, max_samples=None):\n",
    "    \"\"\"Create data formatted for training and validation\n",
    "    \n",
    "    Inputs:\n",
    "    data_csv -- a string, directory of a csv of training/validation data\n",
    "    max_samples -- int, how many samples to include, default is all (useful for debugging)\n",
    "    \n",
    "    Output: (samples, outputs) samples -- a list of vectorized data, outputs -- the model output given\n",
    "    the vectorized data\n",
    "    \"\"\"\n",
    "    with open(\"archive/twitter_training.csv\", 'r') as infile:\n",
    "        training = infile.read().split(\"\\n\")[:max_samples]\n",
    "        formatted = [format_data(data) for data in training]\n",
    "\n",
    "        (outputs, samples) = ([], [])\n",
    "        for data in formatted:\n",
    "            if data == None:\n",
    "                continue\n",
    "            tokens = [token.vector for token in nlp(data[1])]\n",
    "            if len(tokens) == 0:\n",
    "                continue    \n",
    "            outputs.append(data[0])\n",
    "            samples.append(tokens)\n",
    "\n",
    "    return (samples, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "942d6c51-526f-4a36-976e-0fe2976e8c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, outputs = create_data(\"archive/twitter_training.csv\", max_samples=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "791e58aa-04cb-47d9-a6de-4dd69e1ba842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 1.4510656595230103\n",
      "Epoch 5 - Loss: 1.4068183898925781\n",
      "Epoch 10 - Loss: 0.9362459182739258\n",
      "Epoch 15 - Loss: 1.1622061729431152\n",
      "Epoch 20 - Loss: 1.0963518619537354\n",
      "Epoch 25 - Loss: 1.7233542203903198\n",
      "Epoch 30 - Loss: 1.6954896450042725\n",
      "Epoch 35 - Loss: 1.7176799774169922\n",
      "Epoch 40 - Loss: 0.9818764925003052\n",
      "Epoch 45 - Loss: 1.2239439487457275\n",
      "Epoch 50 - Loss: 1.690629243850708\n",
      "Epoch 55 - Loss: 1.6166367530822754\n",
      "Epoch 60 - Loss: 1.6143364906311035\n",
      "Epoch 65 - Loss: 1.5918419361114502\n",
      "Epoch 70 - Loss: 1.713030457496643\n",
      "Epoch 75 - Loss: 1.6680294275283813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiRNN(\n",
       "  (rnn): RNN(300, 32, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, num_outputs=3):\n",
    "        super(BiRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size=self.input_size, hidden_size=self.hidden_size,\\\n",
    "        num_layers=self.num_layers, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        initial_hidden = torch.zeros(2 * self.rnn.num_layers, x.size(0), self.rnn.hidden_size).to(x.device)\n",
    "        out, dummy = self.rnn(x, initial_hidden)\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        return self.fc(out)\n",
    "        \n",
    "model = BiRNN(input_size=300, hidden_size=32, num_layers=1, num_outputs=3)\n",
    "\n",
    "\n",
    "\n",
    "def train(model, samples, outputs, epochs, device):\n",
    "    \"\"\"Trains a bidirectional RNN for a given amount of epochs\"\"\"\n",
    "    model = model.to(device)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    samples = pad_sequence([torch.tensor(sample, dtype=torch.float32) for sample in samples], batch_first=True).to(device)\n",
    "    outputs = torch.tensor(outputs, dtype=torch.long).to(device)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for (sample, actual) in zip(samples, outputs):\n",
    "            sample = sample.unsqueeze(0)\n",
    "            output = model(sample)\n",
    "            output_loss = loss(output, torch.tensor([actual]).to(device))\n",
    "            optimizer.zero_grad()\n",
    "            output_loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += output_loss.item()\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(format(f\"Epoch {epoch} - Loss: {output_loss}\",))\n",
    "\n",
    "    print(format(f\"Epoch {epochs} - Loss: {output_loss}\",))\n",
    "    return model\n",
    "\n",
    "\n",
    "train(model, samples, outputs, 75, \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e9cf7e9-60f9-4475-9493-e48ba9e757f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0773, 0.3812, 0.6793]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = [token.vector for token in nlp(text)]\n",
    "    if len(tokens) == 0:\n",
    "        raise ValueError(\"Input text contains no tokens\")\n",
    "    sample_tensor = torch.tensor(tokens, dtype=torch.float32).unsqueeze(0)  # Add batch dim\n",
    "    return sample_tensor\n",
    "\n",
    "input_text = \"I hate this game so much\"\n",
    "input_tensor = preprocess_text(input_text)\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0a187-6833-4c82-a351-76f58a87f868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
