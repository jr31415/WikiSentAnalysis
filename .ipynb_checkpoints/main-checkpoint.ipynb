{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3d239d6-5aaa-4d66-92b3-d0bcd1d0cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def samplestring_to_num(sampleoutput):\n",
    "    \"\"\"Takes a list (sample, output) where sample is \"Positive\", \"Negative\", \"Neutral\",\n",
    "    or \"Irrelevant\", and returns the same list, but the aforementioned terms are\n",
    "    replaced with 1, -1, 0, or None\n",
    "    \"\"\"\n",
    "    match sampleoutput[0]:\n",
    "        case \"Positive\":\n",
    "            return [1, sampleoutput[1]]\n",
    "        case \"Negative\":\n",
    "            return [-1, sampleoutput[1]]\n",
    "        case \"Neutral\":\n",
    "            return [0, sampleoutput[1]]\n",
    "        case \"Irrelevant\":\n",
    "            return None\n",
    "\n",
    "def format_data(input_data):\n",
    "    \"\"\"Takes unformated data from training/validation, and formats it into a list\n",
    "\n",
    "    Input: input_data -- a string, represeting one line from twitter_training/validation\n",
    "    \"\"\"\n",
    "    data = next(csv.reader([input_data]))[2:]\n",
    "    return samplestring_to_num(data)\n",
    "    \n",
    "def create_data(data_csv, max_samples=None):\n",
    "    \"\"\"Create data formatted for training and validation\n",
    "    \n",
    "    Inputs:\n",
    "    data_csv -- a string, directory of a csv of training/validation data\n",
    "    max_samples -- int, how many samples to include, default is all (useful for debugging)\n",
    "    \n",
    "    Output: (samples, outputs) samples -- a list of vectorized data, outputs -- the model output given\n",
    "    the vectorized data\n",
    "    \"\"\"\n",
    "    with open(\"archive/twitter_training.csv\", 'r') as infile:\n",
    "        training = infile.read().split(\"\\n\")[:max_samples]\n",
    "        formatted = [format_data(data) for data in training]\n",
    "        \n",
    "        outputs = [formatted_data[0] for formatted_data in formatted if formatted_data != None]\n",
    "        samples = [[token.vector for token in nlp(formatted_data[1])] for formatted_data in formatted if formatted_data != None]\n",
    "\n",
    "    return (samples, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "942d6c51-526f-4a36-976e-0fe2976e8c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.8733e-01,  4.0595e-01, -5.1174e-01, -5.5482e-01,  3.9716e-02,\n",
       "        1.2887e-01,  4.5137e-01, -5.9149e-01,  1.5591e-01,  1.5137e+00,\n",
       "       -8.7020e-01,  5.0672e-02,  1.5211e-01, -1.9183e-01,  1.1181e-01,\n",
       "        1.2131e-01, -2.7212e-01,  1.6203e+00, -2.4884e-01,  1.4060e-01,\n",
       "        3.3099e-01, -1.8061e-02,  1.5244e-01, -2.6943e-01, -2.7833e-01,\n",
       "       -5.2123e-02, -4.8149e-01, -5.1839e-01,  8.6262e-02,  3.0818e-02,\n",
       "       -2.1253e-01, -1.1378e-01, -2.2384e-01,  1.8262e-01, -3.4541e-01,\n",
       "        8.2611e-02,  1.0024e-01, -7.9550e-02, -8.1721e-01,  6.5621e-03,\n",
       "        8.0134e-02, -3.9976e-01, -6.3131e-02,  3.2260e-01, -3.1625e-02,\n",
       "        4.3056e-01, -2.7270e-01, -7.6020e-02,  1.0293e-01, -8.8653e-02,\n",
       "       -2.9087e-01, -4.7214e-02,  4.6036e-02, -1.7788e-02,  6.4990e-02,\n",
       "        8.8451e-02, -3.1574e-01, -5.8522e-01,  2.2295e-01, -5.2785e-02,\n",
       "       -5.5981e-01, -3.9580e-01, -7.9849e-02, -1.0933e-02, -4.1722e-02,\n",
       "       -5.5576e-01,  8.8707e-02,  1.3710e-01, -2.9873e-03, -2.6256e-02,\n",
       "        7.7330e-02,  3.9199e-01,  3.4507e-01, -8.0130e-02,  3.3451e-01,\n",
       "        2.7063e-01, -2.4544e-02,  7.2576e-02, -1.8120e-01,  2.3693e-01,\n",
       "        3.9977e-01,  4.5012e-01,  2.7179e-02,  2.7400e-01,  1.4791e-01,\n",
       "       -5.8324e-03,  9.5910e-01, -1.0129e+00,  2.0699e-01,  1.8237e-01,\n",
       "       -2.5234e-01, -2.6261e-01, -3.4799e-01, -2.4051e-02,  4.4470e-01,\n",
       "        5.9226e-02,  4.5561e-01,  1.9700e-01, -4.8327e-01,  8.9523e-02,\n",
       "       -2.2373e-01, -1.5654e-01,  2.1578e-01,  1.1673e-01,  8.2006e-02,\n",
       "       -8.0735e-01,  2.3903e-01, -5.1304e-01, -3.3888e-01, -3.1499e-01,\n",
       "       -1.7272e-01, -6.7020e-01,  2.7096e-01, -4.3241e-01,  4.3103e-02,\n",
       "        2.1233e-02,  1.3350e-02, -6.3938e-02, -2.4957e-01, -2.4938e-01,\n",
       "        3.4812e-01, -7.1321e-02,  2.3375e-01, -9.5384e-02,  5.2488e-01,\n",
       "        6.8175e-01, -1.0214e-01, -1.4914e-01, -7.5697e-02,  1.7248e-01,\n",
       "        2.5440e-01,  1.5760e-01, -5.9125e-01,  2.4300e-01,  6.3962e-01,\n",
       "       -9.3280e-02, -2.7914e-01, -6.6262e-02, -6.7170e-02, -4.0929e-01,\n",
       "       -3.0300e+00,  1.8250e-01,  2.0113e-01,  6.0628e-02, -2.4769e-01,\n",
       "        5.5324e-02, -4.9106e-01,  3.1544e-01, -3.4231e-01, -6.3766e-01,\n",
       "       -3.6129e-01, -5.9029e-02,  1.5510e-01,  4.4577e-02,  2.3572e-01,\n",
       "       -1.7095e-01, -2.2749e-01, -2.3184e-02,  2.3868e-01,  2.8170e-02,\n",
       "        4.2965e-01, -1.2458e-01, -3.6972e-02,  2.0061e-01, -3.1405e-01,\n",
       "       -8.5287e-02, -3.3496e-01, -9.7047e-02, -1.4388e-01,  1.1147e-01,\n",
       "       -4.5232e-01, -2.4217e-01, -1.8245e-01, -6.7292e-01,  2.1933e-02,\n",
       "       -5.4816e-02, -4.6508e-01,  4.7767e-01, -2.4752e-01, -1.5790e-01,\n",
       "        1.1817e-01,  5.6851e-02, -4.9151e-01,  1.5496e-01,  1.6425e-02,\n",
       "        4.1650e-02, -3.4990e-01, -1.5979e-01,  3.9705e-01,  2.2963e-01,\n",
       "        2.4688e-01,  1.9567e-02, -2.8802e-01, -6.9983e-01,  3.2744e-01,\n",
       "        1.0833e-01,  2.4945e-01, -7.8653e-01, -6.1379e-02, -3.7359e-01,\n",
       "       -1.1603e-01, -2.4950e-01,  1.0161e-01,  3.3994e-02,  1.5650e-01,\n",
       "        2.1344e-01, -1.1094e-01, -5.7687e-03,  1.7869e-01, -1.0127e-01,\n",
       "       -1.6891e-02,  3.0001e-01, -3.4116e-01, -3.2390e-02,  4.2514e-02,\n",
       "        1.1850e-01, -1.8337e-01, -6.2865e-01, -2.8021e-01,  4.2351e-01,\n",
       "        1.1277e-01,  1.2121e-03,  1.5710e-01, -3.6321e-01, -4.9251e-01,\n",
       "        1.1653e-01,  2.4024e-01,  1.7712e-01,  6.8700e-02, -4.4137e-01,\n",
       "       -2.9877e-01, -1.2071e-02,  2.8325e-01,  1.0668e-01, -1.8859e-01,\n",
       "       -4.1345e-01, -3.4090e-01,  4.7236e-02, -3.8309e-01,  4.3572e-01,\n",
       "        2.4505e-01,  2.7337e-01, -7.3038e-02,  4.2514e-01, -3.2455e-02,\n",
       "       -3.5211e-01,  4.5691e-01,  1.9433e-01, -1.5230e-01,  4.2675e-01,\n",
       "        2.8795e-01, -5.5969e-01, -1.3031e-01,  8.9844e-02,  4.2605e-01,\n",
       "       -1.9632e-01, -7.1989e-02, -8.0189e-02, -3.0425e-01, -4.6190e-01,\n",
       "        2.8178e-01, -9.9872e-02,  3.5097e-01,  1.6123e-01, -3.6548e-02,\n",
       "       -3.6739e-01, -1.9819e-02,  3.2130e-01,  1.7479e-01,  2.5175e-01,\n",
       "       -7.6439e-03, -9.3786e-02, -3.7852e-01,  4.3725e-01,  2.1288e-01,\n",
       "        2.5096e-01, -1.9613e-01, -2.8865e-01, -5.6726e-03,  4.2795e-01,\n",
       "        2.0625e-01, -3.7701e-02, -1.2200e-01, -7.9253e-02, -1.0290e-01,\n",
       "        1.0558e-02,  4.9880e-01,  2.5382e-01,  1.5526e-01,  1.7951e-03,\n",
       "        1.1633e-01,  7.9300e-02, -3.9142e-01, -3.2483e-01,  6.3451e-01,\n",
       "       -1.8910e-01,  5.4050e-02,  1.6495e-01,  1.8757e-01,  5.3874e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples, output = create_data(\"archive/twitter_training.csv\", max_samples=1)\n",
    "\n",
    "samples[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "791e58aa-04cb-47d9-a6de-4dd69e1ba842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0144, -0.0015, -0.2548]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, num_outputs=3):\n",
    "        super(BiRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size=self.input_size, hidden_size=self.hidden_size,\\\n",
    "        num_layers=self.num_layers, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        initial_hidden = torch.zeros(2 * self.rnn.num_layers, x.size(0), self.rnn.hidden_size)\n",
    "        out, dummy = self.rnn(x, initial_hidden)\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        return self.fc(out)\n",
    "        \n",
    "model = BiRNN(input_size=300, hidden_size=32, num_layers=1, num_outputs=3)\n",
    "model(torch.tensor(samples[0], dtype=torch.float32).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ebab57-ff83-4fac-96ec-d3e8596c03da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9cf7e9-60f9-4475-9493-e48ba9e757f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0a187-6833-4c82-a351-76f58a87f868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
