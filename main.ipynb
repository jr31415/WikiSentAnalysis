{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3d239d6-5aaa-4d66-92b3-d0bcd1d0cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def samplestring_to_num(sampleoutput):\n",
    "    \"\"\"Takes a list (sample, output) where sample is \"Positive\", \"Negative\", \"Neutral\",\n",
    "    or \"Irrelevant\", and returns the same list, but the aforementioned terms are\n",
    "    replaced with 1, -1, 0, or None\n",
    "    \"\"\"\n",
    "    match sampleoutput[0]:\n",
    "        case \"Positive\":\n",
    "            return [0, sampleoutput[1]]\n",
    "        case \"Negative\":\n",
    "            return [1, sampleoutput[1]]\n",
    "        case \"Neutral\":\n",
    "            return [2, sampleoutput[1]]\n",
    "        case \"Irrelevant\":\n",
    "            return None\n",
    "\n",
    "def format_data(input_data):\n",
    "    \"\"\"Takes unformated data from training/validation, and formats it into a list\n",
    "\n",
    "    Input: input_data -- a string, represeting one line from twitter_training/validation\n",
    "    \"\"\"\n",
    "    data = next(csv.reader([input_data]))[2:]\n",
    "    return samplestring_to_num(data)\n",
    "    \n",
    "def create_data(data_csv, max_samples=None):\n",
    "    \"\"\"Create data formatted for training and validation\n",
    "    \n",
    "    Inputs:\n",
    "    data_csv -- a string, directory of a csv of training/validation data\n",
    "    max_samples -- int, how many samples to include, default is all (useful for debugging)\n",
    "    \n",
    "    Output: (samples, outputs) samples -- a list of vectorized data, outputs -- the model output given\n",
    "    the vectorized data\n",
    "    \"\"\"\n",
    "    with open(\"archive/twitter_training.csv\", 'r') as infile:\n",
    "        training = infile.read().split(\"\\n\")[:max_samples]\n",
    "        formatted = [format_data(data) for data in training]\n",
    "\n",
    "        (outputs, samples) = ([], [])\n",
    "        for data in formatted:\n",
    "            if data == None:\n",
    "                continue\n",
    "            tokens = [token.vector for token in nlp(data[1]) if not token.is_space]\n",
    "            if len(tokens) == 0:\n",
    "                continue    \n",
    "            outputs.append(data[0])\n",
    "            samples.append(tokens)\n",
    "\n",
    "        \n",
    "\n",
    "    return (samples, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "942d6c51-526f-4a36-976e-0fe2976e8c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, outputs = create_data(\"archive/twitter_training.csv\", max_samples=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "791e58aa-04cb-47d9-a6de-4dd69e1ba842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 13.011891484260559\n",
      "Epoch 5 - Loss: 12.465294599533081\n",
      "Epoch 10 - Loss: 12.721186339855194\n",
      "Epoch 15 - Loss: 12.709371984004974\n",
      "Epoch 20 - Loss: 12.485625863075256\n",
      "Epoch 25 - Loss: 9.850455284118652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiRNN(\n",
       "  (rnn): RNN(300, 32, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, num_outputs=3):\n",
    "        super(BiRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size=self.input_size, hidden_size=self.hidden_size,\\\n",
    "        num_layers=self.num_layers, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        initial_hidden = torch.zeros(2 * self.rnn.num_layers, x.size(0), self.rnn.hidden_size).to(x.device)\n",
    "        out, dummy = self.rnn(x, initial_hidden)\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        return self.fc(out)\n",
    "        \n",
    "model = BiRNN(input_size=300, hidden_size=32, num_layers=1, num_outputs=3)\n",
    "\n",
    "\n",
    "\n",
    "def train(model, samples, outputs, epochs, device):\n",
    "    \"\"\"Trains a bidirectional RNN for a given amount of epochs\"\"\"\n",
    "    model = model.to(device)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    samples = pad_sequence([torch.tensor(sample, dtype=torch.float32) for sample in samples], batch_first=True).to(device)\n",
    "    outputs = torch.tensor(outputs, dtype=torch.long).to(device)\n",
    "\n",
    "    dataset = TensorDataset(samples, outputs)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for (sample, actual) in dataloader:\n",
    "            sample = sample.to(device)\n",
    "            actual = actual.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs= model(sample)\n",
    "            output_loss = loss(outputs, actual)\n",
    "            output_loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += output_loss.item()\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(format(f\"Epoch {epoch} - Loss: {epoch_loss}\",))\n",
    "\n",
    "    print(format(f\"Epoch {epochs} - Loss: {epoch_loss}\",))\n",
    "    return model\n",
    "\n",
    "\n",
    "train(model, samples, outputs, 25, \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0a187-6833-4c82-a351-76f58a87f868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
